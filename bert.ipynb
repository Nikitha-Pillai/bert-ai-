{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitha-Pillai/bert-ai-/blob/main/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "061fd5afcad54ce1aed1b8dbb612c3f7",
            "4a65a094ab3e4337aee44dbeb45eaaa7",
            "76053d4be9e6499286539f1826354ea5",
            "d2bd508a84ba4a5298aab2eda75fd2a2",
            "65610ff6dd7349e0842cf1050e5fd4b9",
            "cd8429b4b728416b8905d1b4f8d490e0",
            "49e4b4738a694d52b57dda32e54a19d3",
            "00856da443dd4021971b8a5c063d7ae2",
            "505ea48d1bba4fd0bb164964bda86bc5",
            "4b0db01ec57e49a4a9868f4dc1dd8815",
            "c7d300af0ace47b080c22a94bf3899db",
            "4e92d1d6c5b64ce7916942a69a82dfd9",
            "e3fab7aacd854a03a1db1fb135b5b99e",
            "f51d4c38b3af44e481657293185093ea",
            "730750206cd1474b88195d09ca489973",
            "cb088bb2cece456898c7726efd3c79d2",
            "a4c1813f0e6541f3bf60dd361188407a",
            "02528a490a5d45e49d466249caffe6c1",
            "1b7004996d614678a43ef58f6971cef0",
            "8d54ddadde4e49ec987d5e84e61024ff",
            "c67e02d765e04db5ac65975d37318307",
            "bb15b442721d4113a6a6042b2760e88c",
            "d21c2c7a81b14a84b93828188958f9e7",
            "9c1da361830345c7bf9fdaec55c18973",
            "2978939fa2dd42348e0f8d41a240ca62",
            "d9f5868a924248a49013948ede543c62",
            "379b0071f8be4320a37ea66c7266c349",
            "81b0d964638a488693cb9da24e8d5859",
            "4f699107b35940c8b293862cc38c0d0b",
            "a545f94bc37142c7bf74a49a4e8c6a2f",
            "0eea3a03655b4afa8ffe8bb4594293fe",
            "b03816d6fe25424790b2f90996f69b9a",
            "4e377ccd89334e6abd5d137c39fa2635",
            "d35780f89fcf4dd6bdf2c1accd918aa5",
            "3c132037966340eb8c6c075882741c93",
            "e597b289f0a549a195830786008cee08",
            "e6a599c3319549d98b5765a37c522b07",
            "e0bfde5b1a1e43ceac6f33b53e351436",
            "0ea3696985ca4b7dbe10e2f0520dd5b4",
            "2081b6bc05e8419d825c05aeb8da99b4",
            "1ccf6ea65208474382451844f3aab366",
            "50949fb979fa4ae1a0a98b94c23c0994",
            "e16a6ef4a35a4804a61f774f0d818b20",
            "fdc15373c34f433086d187ccd2ed3b20",
            "4fed6cf7650c45b7923b31e68cdd7d4a",
            "a810738f443a4bd792ef0d4957ba9b1b",
            "8abf4c72d0f6438c8d2f78a7cdda4a87",
            "5a1c31d23fd049c593d54dd1ba425671",
            "6ad4420d090f4c9784eba6135d39f40f",
            "38cbf8b3820d455084207ffa4f9ae489",
            "2432bc0024614187bf0834799be29e42",
            "6aea4728b15246c7827f14cfe35160b0",
            "141f67b2a88f4962b79ace1d742f0267",
            "ede1c959dbbc4c75825f54b11460e0cb",
            "c0547f8d0589470f9bcd03d73ada142e",
            "7887ab5316624b39ab7ee6ec2126bc9f",
            "34c35f894fdc47818980ffe8fea1b82a",
            "0afbbf9c40ab4ba49b1645b3f3b97470",
            "5af225dfd7ae43b79a3bb9a265bb55e7",
            "2b91ad2aff414cf6a374b3499ff5444e",
            "23b598d31a1b4842953a2acc978cade9",
            "8b1fd561a8724e338533f7cc2684b5bc",
            "721b274025334774baa6154d8d0b252e",
            "0222c723d66e4ace8deef9f34270fbcc",
            "787cfebf5a92442bb70e3c45fbf95f10",
            "a89a1b6469e24dfeb77bf24488b3145a",
            "7536207b43d14dce97cdeff90340d9ea",
            "5b4bb0189cca4d97ae3d978551acea1d",
            "6b0e803fbbba4f1fbfde817a5a53c07f",
            "3ef1c11726624d7b858e4e5dd24dbddf",
            "f494b2e7f42c44959eac604cfe938219",
            "0de67dd8e3a247b0ab03691b0d7e9842",
            "8af11e6d5a044ce5961eebb83a3de1c5",
            "e0dbe80bedab4674b9cb262f9324a530",
            "edad4ec0908246ea96ce8c9f557c4cf9",
            "c4f5dbb6304e40c18ee11715103c279f",
            "349587484fa64e09a0b20828d889f62a",
            "67c1759762f647109f44fc7a9f42772a",
            "08cfc704faf747c3af7f78b7903f80b8",
            "4edfd1058b5b4033949de43640598d3d",
            "fc826d3660584976ba08f4e5ce40b131",
            "7253f3eb52af4b759d9ca83b8836e063",
            "6b7888fa8a1f4b048707ccb6d6b34f96",
            "2b4f724d78b64d628da77671fb6879fa",
            "1ac9a2a3a74a4ec88dabda72d5873312",
            "6d8acea7b6fe4f218023b2c66a7162c4",
            "9691bc3bb8d94b968352c8227199c8d2",
            "a51e623ec113469e843b2b047e6b30e2",
            "e1f3952cce994d2988c0d39c08acbb87",
            "490357355c69409dbeadd87d3783e610",
            "bd2fe971a1054215aa1e4f65fdeb8b62",
            "94cf47e722054d88bfe258bfd91c9c1c",
            "298804f63b8d4e5e955be428f1b84293",
            "4d89b4342c4041ffb04367486c05a935",
            "160fda1e68fa44559a3bbfece68a4e57",
            "6e3c120db3c748d59891c8c62ad7fd12",
            "e214dd0447db4780911c74748bae855e",
            "a0ecb74c9eb247c080d29802bee8dd5c",
            "e316991a4304498681e2f8947093b541",
            "b2bbd83e95824f5f85a83a27775f9dc4",
            "faf97302c56f4c439f076dbbeaba752d",
            "bdc9987d6bff4b1f87200eef7e7832d2",
            "497dd17e03714e81978676cd4e8232aa",
            "14e14c2a19cf456680d68db966d1b28f",
            "46211c89b81a41d6a59f8eaaef06a592",
            "318e27b2f13846bcb4547bf4f2f8b76c",
            "f08633749feb4e65b22fe420cf86bd69",
            "31f5b69186a74df79eda1fe868d58301",
            "a6f1d97e3a4d41f78821c74261bc6027",
            "37af31f4def34696851f6fd1db8fa240",
            "69aaf1793c884d82af604bbaa1f549fb",
            "02b6f434ec294bacb4955809809f25bc",
            "9e28968978f1488590da2a328a89e76d",
            "c79614401cbf4f8481982cb7f88e0975",
            "e37399167e024c0f8e3199c4c1fdc8a3",
            "66765e4e26f64efeaf6db88796236fd0",
            "de39c2b25cdb486f8a10f451ae8b4b89",
            "6576cc6ff36b4f348051cc5b7ecb04d9",
            "df87ab3887344f478a280b1f0cd59e06",
            "10c42c2856cb4d3d8e0dbffbf80bc6a4",
            "da58811470824e57bd3084b7f55e98b1",
            "b7931ccd6b6e4c14a4b2132c84c25346",
            "d6c05d67c02f41518117e6f15f0218cd",
            "626807effdc04079b5819e384fa2fe4f",
            "8dff26096a2a47888abc3d5075b8d2f9",
            "61f466d9a7b54d1a97861d275bb3ddef",
            "0ba2ba238cba4b00bd30466538d09815",
            "56051805a108469685a12d80df71b07b",
            "da00e582e64446b3ab909a295d5b880d",
            "d0bfb51b875b4f38b41f48afed5a18d5",
            "7560f0d0332f47558838e010c6ce7fc6",
            "2e7c6d7ed3fc42bc8ecc70daa4415bb0",
            "f1f7b86e787b4006807db157cb2e18d1",
            "e3fca2ac12c44c2fb717efbf02fa6738",
            "3c143b8f8cd44399a067157bd3e68b3a",
            "69fa92be83a8486fa1677be301cc1718",
            "08aa99eab4834e849ecd6b809b8fdb15",
            "bc1373e0546c4bceb31af64fe4a7b412",
            "d5b0825fb0644af1945dea99dbeed8cc",
            "adfac409eee44ff7a5a1492a6918a4fd",
            "666663753f16405292ab3b2b3eb2253d",
            "4bdeba9d60564afbb0bbc11d0a611ef5",
            "ceb40993792a4e7a8b9f2f139f1be777"
          ]
        },
        "id": "XtB0juU4Uh1K",
        "outputId": "c5926e5c-5eb6-4fc9-ad0b-dd0cc6923180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ File found: /content/drive/MyDrive/data2/combineddataset.xlsx\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "061fd5afcad54ce1aed1b8dbb612c3f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/122 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Remaining samples after duplicate removal: 3431\n",
            "\n",
            "üìò Fold 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e92d1d6c5b64ce7916942a69a82dfd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2744 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d21c2c7a81b14a84b93828188958f9e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/687 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚û°Ô∏è Fold 1 - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:34, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.526800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.200500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.206100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9461, Precision=0.9398, Recall=0.9483, F1=0.9440\n",
            "\n",
            "‚û°Ô∏è Fold 1 - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:35, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.249700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.189600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.200900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9461, Precision=0.9398, Recall=0.9483, F1=0.9440\n",
            "\n",
            "‚û°Ô∏è Fold 1 - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:45, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.237600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.195400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9461, Precision=0.9424, Recall=0.9453, F1=0.9439\n",
            "\n",
            "üìò Fold 2/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d35780f89fcf4dd6bdf2c1accd918aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2745 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fed6cf7650c45b7923b31e68cdd7d4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚û°Ô∏è Fold 2 - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.185100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.236200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:14]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9417, Precision=0.9383, Recall=0.9383, F1=0.9383\n",
            "\n",
            "‚û°Ô∏è Fold 2 - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.195200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.213900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9431, Precision=0.9412, Recall=0.9383, F1=0.9397\n",
            "\n",
            "‚û°Ô∏è Fold 2 - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.164100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.205200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9431, Precision=0.9412, Recall=0.9383, F1=0.9397\n",
            "\n",
            "üìò Fold 3/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7887ab5316624b39ab7ee6ec2126bc9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2745 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7536207b43d14dce97cdeff90340d9ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚û°Ô∏è Fold 3 - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.508300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.184200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.258200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9577, Precision=0.9700, Recall=0.9357, F1=0.9525\n",
            "\n",
            "‚û°Ô∏è Fold 3 - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:34, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.220300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9577, Precision=0.9700, Recall=0.9357, F1=0.9525\n",
            "\n",
            "‚û°Ô∏è Fold 3 - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.176600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9592, Precision=0.9670, Recall=0.9421, F1=0.9544\n",
            "\n",
            "üìò Fold 4/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67c1759762f647109f44fc7a9f42772a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2745 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1f3952cce994d2988c0d39c08acbb87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚û°Ô∏è Fold 4 - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.524500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.193700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.267400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9577, Precision=0.9513, Recall=0.9544, F1=0.9528\n",
            "\n",
            "‚û°Ô∏è Fold 4 - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.253000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9577, Precision=0.9513, Recall=0.9544, F1=0.9528\n",
            "\n",
            "‚û°Ô∏è Fold 4 - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.223300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9563, Precision=0.9511, Recall=0.9511, F1=0.9511\n",
            "\n",
            "üìò Fold 5/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2bbd83e95824f5f85a83a27775f9dc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2745 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69aaf1793c884d82af604bbaa1f549fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚û°Ô∏è Fold 5 - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.520500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9548, Precision=0.9673, Recall=0.9338, F1=0.9502\n",
            "\n",
            "‚û°Ô∏è Fold 5 - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.198900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.208500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9519, Precision=0.9610, Recall=0.9338, F1=0.9472\n",
            "\n",
            "‚û°Ô∏è Fold 5 - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='344' max='344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [344/344 03:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.199300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.189100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9504, Precision=0.9609, Recall=0.9306, F1=0.9455\n",
            "\n",
            "‚úÖ Cross-Validation Results (last epoch of each fold):\n",
            "Average Accuracy:  0.9510\n",
            "Average Precision: 0.9525\n",
            "Average Recall:    0.9415\n",
            "Average F1:        0.9469\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7931ccd6b6e4c14a4b2132c84c25346",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2744 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1f7b86e787b4006807db157cb2e18d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/687 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìò Final Model Training\n",
            "\n",
            "‚û°Ô∏è Final Model - Epoch 1/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 08:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 1: Accuracy=0.9461, Precision=0.9371, Recall=0.9514, F1=0.9442\n",
            "\n",
            "‚û°Ô∏è Final Model - Epoch 2/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 2: Accuracy=0.9447, Precision=0.9422, Recall=0.9422, F1=0.9422\n",
            "\n",
            "‚û°Ô∏è Final Model - Epoch 3/3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='343' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [343/343 03:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics after Epoch 3: Accuracy=0.9461, Precision=0.9371, Recall=0.9514, F1=0.9442\n",
            "‚úÖ Model saved to /content/drive/MyDrive/data2/bert_model\n"
          ]
        }
      ],
      "source": [
        "# =============================================\n",
        "# üöÄ BERT Model - Binary Text Classification\n",
        "# =============================================\n",
        "\n",
        "!pip install -q transformers==4.57.0 datasets pandas openpyxl torch scikit-learn sentence-transformers\n",
        "\n",
        "# ===================== Imports =====================\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# ===================== Mount Google Drive =====================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ===================== Load Excel File =====================\n",
        "file_path = \"/content/drive/MyDrive/data2/combineddataset.xlsx\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File not found at {file_path}\")\n",
        "else:\n",
        "    print(f\"‚úÖ File found: {file_path}\")\n",
        "\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# ===================== Preprocess Text =====================\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', str(text))  # remove non-ASCII\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()         # remove extra spaces\n",
        "    return ' '.join(text.split()[:500])              # limit to 500 words\n",
        "\n",
        "df['subject'] = df['subject'].astype(str).apply(preprocess_text)\n",
        "df['body'] = df['body'].astype(str).apply(preprocess_text)\n",
        "df['text'] = (df['subject'] + \" \" + df['body']).str.strip()\n",
        "\n",
        "df = df.dropna(subset=['text', 'label'])\n",
        "df = df[df['text'].str.strip() != '']\n",
        "df = df[~df['text'].str.contains('#ERROR!', na=False)]\n",
        "df = df.drop_duplicates(subset=['text'])\n",
        "\n",
        "# Optional: Add small label noise (5%)\n",
        "def add_label_noise(label, noise_rate=0.05):\n",
        "    if random() < noise_rate:\n",
        "        return 1 - label\n",
        "    return label\n",
        "\n",
        "df['label'] = df['label'].apply(lambda x: add_label_noise(int(x)))\n",
        "\n",
        "# ===================== Remove Near-Duplicates =====================\n",
        "model_embeddings = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model_embeddings.encode(df['text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
        "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "threshold = 0.9\n",
        "to_drop = set()\n",
        "for i in range(len(df)):\n",
        "    if i in to_drop:\n",
        "        continue\n",
        "    similar = torch.where(cosine_scores[i] > threshold)[0].tolist()\n",
        "    for j in similar:\n",
        "        if i != j:\n",
        "            to_drop.add(j)\n",
        "df = df.drop(df.index[list(to_drop)]).reset_index(drop=True)\n",
        "print(f\"‚úÖ Remaining samples after duplicate removal: {len(df)}\")\n",
        "\n",
        "# ===================== Tokenization =====================\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "# ===================== Metrics =====================\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "# ===================== 5-Fold Cross-Validation =====================\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
        "\n",
        "num_epochs = 3  # Number of epochs per fold\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(df)):\n",
        "    print(f\"\\nüìò Fold {fold+1}/5\")\n",
        "\n",
        "    train_data = df.iloc[train_idx]\n",
        "    val_data = df.iloc[val_idx]\n",
        "\n",
        "    train_dataset = Dataset.from_pandas(train_data[['text', 'label']])\n",
        "    val_dataset = Dataset.from_pandas(val_data[['text', 'label']])\n",
        "\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    train_dataset = train_dataset.remove_columns(['text'])\n",
        "    val_dataset = val_dataset.remove_columns(['text'])\n",
        "    train_dataset.set_format('torch')\n",
        "    val_dataset.set_format('torch')\n",
        "\n",
        "    # Initialize BERT\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "    # Freeze first 8 layers to speed up training\n",
        "    for name, param in model.bert.encoder.layer[:8].named_parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'/content/drive/MyDrive/data2/bert_fold_{fold+1}',\n",
        "        num_train_epochs=1,  # Train one epoch at a time manually\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=100,\n",
        "        save_strategy=\"epoch\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train manually for each epoch to print metrics\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n‚û°Ô∏è Fold {fold+1} - Epoch {epoch+1}/{num_epochs}\")\n",
        "        trainer.train(resume_from_checkpoint=False)\n",
        "        eval_metrics = trainer.evaluate()\n",
        "        print(f\"Metrics after Epoch {epoch+1}: \"\n",
        "              f\"Accuracy={eval_metrics['eval_accuracy']:.4f}, \"\n",
        "              f\"Precision={eval_metrics['eval_precision']:.4f}, \"\n",
        "              f\"Recall={eval_metrics['eval_recall']:.4f}, \"\n",
        "              f\"F1={eval_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "        # Save last epoch metrics for summary\n",
        "        if epoch == num_epochs - 1:\n",
        "            accuracy_list.append(eval_metrics['eval_accuracy'])\n",
        "            precision_list.append(eval_metrics['eval_precision'])\n",
        "            recall_list.append(eval_metrics['eval_recall'])\n",
        "            f1_list.append(eval_metrics['eval_f1'])\n",
        "\n",
        "print(\"\\n‚úÖ Cross-Validation Results (last epoch of each fold):\")\n",
        "print(f\"Average Accuracy:  {np.mean(accuracy_list):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precision_list):.4f}\")\n",
        "print(f\"Average Recall:    {np.mean(recall_list):.4f}\")\n",
        "print(f\"Average F1:        {np.mean(f1_list):.4f}\")\n",
        "\n",
        "# ===================== Final Model Training =====================\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
        "val_dataset = Dataset.from_pandas(val_df[['text', 'label']])\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "train_dataset = train_dataset.remove_columns(['text'])\n",
        "val_dataset = val_dataset.remove_columns(['text'])\n",
        "train_dataset.set_format('torch')\n",
        "val_dataset.set_format('torch')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "for name, param in model.bert.encoder.layer[:8].named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/data2/bert_final_model',\n",
        "    num_train_epochs=1,  # manual loop\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"\\nüìò Final Model Training\")\n",
        "num_epochs_final = 3\n",
        "for epoch in range(num_epochs_final):\n",
        "    print(f\"\\n‚û°Ô∏è Final Model - Epoch {epoch+1}/{num_epochs_final}\")\n",
        "    trainer.train(resume_from_checkpoint=False)\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"Metrics after Epoch {epoch+1}: \"\n",
        "          f\"Accuracy={eval_metrics['eval_accuracy']:.4f}, \"\n",
        "          f\"Precision={eval_metrics['eval_precision']:.4f}, \"\n",
        "          f\"Recall={eval_metrics['eval_recall']:.4f}, \"\n",
        "          f\"F1={eval_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "# ===================== Save Model =====================\n",
        "save_path = '/content/drive/MyDrive/data2/bert_model'\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"‚úÖ Model saved to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU70Ltda2NrP",
        "outputId": "52a150b6-95fe-4273-fb16-2af0222ad962"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "config.json\t   special_tokens_map.json  vocab.txt\n",
            "model.safetensors  tokenizer_config.json\n",
            "‚úÖ BERT model and tokenizer loaded successfully!\n",
            "\n",
            "üìß Manual Email Testing (press Enter on body to stop):\n",
            "\n",
            "===============================\n",
            "Subject: Dear Students,\n",
            "Body: The lecture videos for Week 12 have been uploaded for the co...\n",
            "Prediction: Legitimate\n",
            "Confidence: 0.8958\n",
            "Probabilities ‚Üí Phishing: 0.1042, Legitimate: 0.8958\n",
            "===============================\n",
            "\n",
            "===============================\n",
            "Subject: Dear, nandanaanandp@gmail.com!\n",
            "Body: Dear, nandanaanandp@gmail.com!  We are pleased to inform you...\n",
            "Prediction: Phishing\n",
            "Confidence: 0.9908\n",
            "Probabilities ‚Üí Phishing: 0.9908, Legitimate: 0.0092\n",
            "===============================\n",
            "\n",
            "===============================\n",
            "Subject: PayPal account unusual sign-in activity\n",
            "Body: PayPal account Unusual sign-in activity We detected somethin...\n",
            "Prediction: Phishing\n",
            "Confidence: 0.9956\n",
            "Probabilities ‚Üí Phishing: 0.9956, Legitimate: 0.0044\n",
            "===============================\n",
            "\n",
            "===============================\n",
            "Subject: job posting - apple-iss research center\n",
            "Body: FAX: +27 837 697 560...\n",
            "Prediction: Legitimate\n",
            "Confidence: 0.9665\n",
            "Probabilities ‚Üí Phishing: 0.0335, Legitimate: 0.9665\n",
            "===============================\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "#  Install required libraries\n",
        "# ==============================\n",
        "!pip install transformers torch\n",
        "\n",
        "# ==============================\n",
        "#  Import libraries\n",
        "# ==============================\n",
        "import re\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # Disable wandb\n",
        "from google.colab import drive\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# ==============================\n",
        "#  Mount Google Drive\n",
        "# ==============================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================\n",
        "#  Verify model folder\n",
        "# ==============================\n",
        "!ls \"/content/drive/MyDrive/data2/bert_model/\"\n",
        "\n",
        "# ==============================\n",
        "#  Load the trained BERT model and tokenizer\n",
        "# ==============================\n",
        "model_path = '/content/drive/MyDrive/data2/bert_model'\n",
        "try:\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    print(\"‚úÖ BERT model and tokenizer loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: Failed to load model or tokenizer from {model_path}. Please check the path.\")\n",
        "    print(\"To locate the model folder, run: !find '/content/drive/MyDrive/' -name 'bert_model'\")\n",
        "    raise e\n",
        "\n",
        "# ==============================\n",
        "#  Text preprocessing (same as training)\n",
        "# ==============================\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Remove non-ASCII characters\n",
        "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "        # Collapse multiple spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        # Limit to first 200 words\n",
        "        words = text.split()[:200]\n",
        "        return ' '.join(words)\n",
        "    return ''\n",
        "\n",
        "# ==============================\n",
        "#  Prediction function\n",
        "# ==============================\n",
        "def predict_email(text, subject=\"\"):\n",
        "    # Combine subject + body\n",
        "    full_text = preprocess_text(subject + ' ' + text)\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        full_text,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # Move model and tensors to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "    prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    label = \"Phishing\" if prediction == 1 else \"Legitimate\"\n",
        "    confidence = probabilities[prediction]\n",
        "\n",
        "    return label, confidence, probabilities\n",
        "\n",
        "# ==============================\n",
        "#  Manual testing loop\n",
        "# ==============================\n",
        "print(\"\\nüìß Manual Email Testing (press Enter on body to stop):\")\n",
        "while True:\n",
        "    subject = input(\"Enter email subject (or leave blank): \")\n",
        "    body = input(\"Enter email body: \")\n",
        "    if not body.strip():\n",
        "        print(\"üõë No email body provided. Stopping manual testing.\")\n",
        "        break\n",
        "\n",
        "    label, confidence, probabilities = predict_email(body, subject)\n",
        "\n",
        "    print(\"\\n===============================\")\n",
        "    print(f\"Subject: {subject[:60] if subject else '(no subject)'}\")\n",
        "    print(f\"Body: {body[:60]}...\")\n",
        "    print(f\"Prediction: {label}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "    print(f\"Probabilities ‚Üí Phishing: {probabilities[1]:.4f}, Legitimate: {probabilities[0]:.4f}\")\n",
        "    print(\"===============================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxA5BWNkVjDD",
        "outputId": "7f100ab9-c80f-44a1-dabb-ca4a8fb38f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cleaned metadata in /content/drive/MyDrive/Colab Notebooks/bert.ipynb\n"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/bert.ipynb\"  # üëà change if needed\n",
        "\n",
        "nb = nbformat.read(path, as_version=nbformat.NO_CONVERT)\n",
        "if 'widgets' in nb['metadata']:\n",
        "    del nb['metadata']['widgets']\n",
        "nbformat.write(nb, path)\n",
        "\n",
        "print(\"‚úÖ Cleaned metadata in\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZPTyRVoWbO6",
        "outputId": "51bf0cbe-a191-4603-f4f0-a01c1a2cd71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\t\t\t\t     'model (1).safetensors'\n",
            " data2\t\t\t\t\t\t      Models\n",
            " Datasets\t\t\t\t\t      model.safetensors\n",
            " events.out.tfevents.1759671799.244238003db4.1231.3\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNiLD04kt4sGahJ7b/pf60v",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}